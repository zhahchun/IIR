{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import textwrap as tw\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test1.xml', 'test2.xml', 'test3.xml']\n"
     ]
    }
   ],
   "source": [
    "path = 'doc/'\n",
    "files = os.listdir(path)\n",
    "ls_xml = []\n",
    "\n",
    "for i in files:\n",
    "    if '.xml' in i:\n",
    "        ls_xml.append(i)\n",
    "\n",
    "print(ls_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_content(ls_xml, path, df):\n",
    "    \n",
    "    for xml in ls_xml:\n",
    "        tree = et.parse(path + xml)\n",
    "        root = tree.getroot()\n",
    "        ct_at =0        \n",
    "        \n",
    "        for x in root:\n",
    "            ct_as =0\n",
    "            # print('xml:',xml,'ct_at:', ct_at)\n",
    "            \n",
    "            if x.tag == 'PubmedArticle':\n",
    "                \n",
    "                # Article的位置不固定\n",
    "                cnt = 0\n",
    "                for child in root[ct_at][0]:\n",
    "                    if child.tag == 'Article':\n",
    "                        break\n",
    "                    cnt += 1\n",
    "                \n",
    "                for y in root[ct_at][0][cnt]:\n",
    "                    # print(y.tag)\n",
    "                    title = ''\n",
    "                    abstract = ''\n",
    "                    \n",
    "                    if y.tag == 'ArticleTitle':\n",
    "                        title = y.text\n",
    "                        # print('Title:',title)\n",
    "                        df.loc[len(df)] = [xml, ct_at, title, abstract]\n",
    "\n",
    "                    elif y.tag == 'Abstract':\n",
    "                        for z in root[ct_at][0][cnt][ct_as].findall('AbstractText'):\n",
    "                            temp = tw.fill(z.text, initial_indent = '  ')\n",
    "                            temp = temp + '\\n'\n",
    "                            abstract += temp\n",
    "\n",
    "                        # print(abstract)\n",
    "                        df.loc[len(df)-1, 'Content'] = abstract          \n",
    "                        break\n",
    "                        \n",
    "                    ct_as += 1\n",
    "                    \n",
    "            ct_at += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.head(10):          XML ID                                              Title  \\\n",
      "0  test1.xml  0               Treatment for COVID-19: An overview.   \n",
      "1  test2.xml  0  Epidemiology of COVID-19 infection in young ch...   \n",
      "2  test3.xml  0  Neuropsychiatric aspects of COVID-19 pandemic:...   \n",
      "\n",
      "                                             Content  \n",
      "0    Coronavirus disease 2019 (COVID-19) is an in...  \n",
      "1    Emerging evidence suggests young children ar...  \n",
      "2    Corona virus disease (COVID-19) has been dec...  \n"
     ]
    }
   ],
   "source": [
    "columns = [\"XML\",\"ID\",\"Title\",\"Content\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "df01 = pd.DataFrame(columns = columns)\n",
    "df02 = pd.DataFrame(columns = columns)\n",
    "\n",
    "df = get_xml_content(ls_xml, path, df)\n",
    "print('df.head(10):',df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(f01, f02):\n",
    "    \n",
    "    df01 = df[df['XML'] == f01]\n",
    "    cont01 = df01.iloc[0]['Content']\n",
    "    # print(cont01)\n",
    "    df02 = df[df['XML'] == f02]\n",
    "    cont02 = df02.iloc[0]['Content']\n",
    "    # print(cont01)\n",
    "    \n",
    "    if cont01 == cont02:\n",
    "        print('The 2 files are the same.')\n",
    "    else:\n",
    "        sent01 = sent_tokenize(cont01)\n",
    "        sent02 = sent_tokenize(cont02)\n",
    "        s_len = min([len(sent01), len(sent02)])\n",
    "\n",
    "        for i in range(0, s_len):\n",
    "            if sent01[i] != sent02[i]:\n",
    "                s01, s02 = sent01[i], sent02[i]\n",
    "                word01 = word_tokenize(s01)\n",
    "                word02 = word_tokenize(s02)\n",
    "                w_len = min([len(word01), len(word02)])\n",
    "                \n",
    "                for j in range(0, w_len):\n",
    "                    if word01[j] != word02[j]:\n",
    "                        ind = j                            \n",
    "                        break\n",
    "                        \n",
    "                colored_text = []\n",
    "                for k in range(0, len(word01)):\n",
    "            \n",
    "                        if k == ind:\n",
    "                            colored_text.append(colored(word01[k], 'grey','on_yellow'))\n",
    "\n",
    "                        else:\n",
    "                            colored_text.append(word01[k])\n",
    "\n",
    "                s01 = \" \".join(colored_text)\n",
    "                colored_text = []\n",
    "\n",
    "                for k in range(0, len(word02)):\n",
    "            \n",
    "                        if k == ind:\n",
    "                            colored_text.append(colored(word02[k], 'grey','on_yellow'))\n",
    "\n",
    "                        else:\n",
    "                            colored_text.append(word02[k])\n",
    "\n",
    "                s02 = \" \".join(colored_text)\n",
    "                colored_text = []\n",
    "                break\n",
    "                \n",
    "        print('\\nThe 2 files are different, starting from sentences: \\n[file01]', s01, '\\n[file02]', s02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 files to compare (seperated by a space): test1.xml test2.xml\n",
      "\n",
      "The 2 files are different, starting from sentences: \n",
      "[file01] \u001b[43m\u001b[30mCoronavirus\u001b[0m disease 2019 ( COVID-19 ) is an infectious disease caused by coronavirus-2 ( SARS-CoV-2 ) that causes a severe acute respiratory syndrome , a characteristic hyperinflammatory response , vascular damage , microangiopathy , angiogenesis and widespread thrombosis . \n",
      "[file02] \u001b[43m\u001b[30mEmerging\u001b[0m evidence suggests young children are at greater risk of COVID-19 infection than initially predicted .\n"
     ]
    }
   ],
   "source": [
    "files = input('2 files to compare (seperated by a space): ')\n",
    "files = re.split(r'(\\s)',files)\n",
    "while ' ' in files:\n",
    "    files.remove(' ')\n",
    "f01, f02 = files[0], files[1]\n",
    "\n",
    "compare(f01, f02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
