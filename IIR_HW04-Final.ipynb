{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d2f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4197acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import models, corpora\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06685e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from termcolor import colored\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c794a341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "!\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~’—“”‘\n"
     ]
    }
   ],
   "source": [
    "print(type(punctuation))\n",
    "punct = punctuation + '’' + '—' + '“' + '”' + '‘'\n",
    "punct = punct.replace('-', \"\")\n",
    "print(punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0b022",
   "metadata": {},
   "source": [
    "# CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49341a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_file, df_weight, sen_list, unst_sen_list):\n",
    "    s_cnt = 0\n",
    "    for i, row in df_file.iterrows():\n",
    "        #['id', 'url', 'headline', 'abstract'] \n",
    "\n",
    "        sen = str(row['headline'])\n",
    "        sen = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', sen)\n",
    "        for s in sen:\n",
    "            s_cnt += 1\n",
    "            ori_s = s\n",
    "            # print('ori_s:', ori_s)\n",
    "\n",
    "            stem_w = []\n",
    "            s_p = ''.join(w for w in s if w not in punct)\n",
    "            s_p = s_p.replace('-', \" \")\n",
    "            token = word_tokenize(s_p)\n",
    "\n",
    "            # filter numbers, 移除 4碼年份以外的 word\n",
    "            for w in token:\n",
    "                try:\n",
    "                    if str(int(float(w))).isnumeric() and len(w) != 4:\n",
    "                        token.remove(w)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            num_word = len(token)\n",
    "            unst_s = \" \".join(token)\n",
    "            # print('unst_s:', unst_s)\n",
    "\n",
    "            for w in token:\n",
    "                stem_w.append(ps.stem(w))\n",
    "\n",
    "            # print('stem_w:', stem_w)\n",
    "            s = \" \".join(stem_w)\n",
    "            sen_list.append(s)\n",
    "            unst_sen_list.append(unst_s)\n",
    "            # print('s_cnt:', s_cnt, '\\n ori_s:', ori_s, '\\n s:', s)\n",
    "            df_weight.loc[len(df_weight)] = [s_cnt, ori_s, stem_w, num_word]\n",
    "\n",
    "\n",
    "        sen = str(row['abstract'])  \n",
    "        sen = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', sen)\n",
    "        for s in sen:\n",
    "            s_cnt += 1\n",
    "            ori_s = s\n",
    "\n",
    "            stem_w = []\n",
    "            s_p = ''.join(w for w in s if w not in punct)\n",
    "            s_p = s_p.replace('-', \" \")\n",
    "            token = word_tokenize(s_p)\n",
    "\n",
    "            for w in token:\n",
    "                try:\n",
    "                    if str(int(float(w))).isnumeric() and len(w) != 4:\n",
    "                        token.remove(w)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            num_word = len(token)\n",
    "            unst_s = \" \".join(token)\n",
    "\n",
    "            for w in token:\n",
    "                stem_w.append(ps.stem(w))\n",
    "\n",
    "            s = \" \".join(stem_w)\n",
    "            sen_list.append(s)\n",
    "            unst_sen_list.append(unst_s)\n",
    "            df_weight.loc[len(df_weight)] = [s_cnt, ori_s, stem_w, num_word]\n",
    "            \n",
    "    return df_weight, sen_list, unst_sen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de211ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    s_id                                      original_sent  \\\n",
      "471  472  When President Barack Obama gave his farewell ...   \n",
      "472  473                     For Elite Golfers, Money Talks   \n",
      "473  474  Sponsors have long paid players to compete in ...   \n",
      "474  475  Art Basel, Swiss Centerpiece of the Trade’s Ye...   \n",
      "475  476  Dealers were looking to the event as a bellwet...   \n",
      "\n",
      "                                          stemmed_sent num_word  \n",
      "471  [when, presid, barack, obama, gave, hi, farewe...       56  \n",
      "472                   [for, elit, golfer, money, talk]        5  \n",
      "473  [sponsor, have, long, paid, player, to, compet...       24  \n",
      "474  [art, basel, swiss, centerpiec, of, the, trade...       10  \n",
      "475  [dealer, were, look, to, the, event, as, a, be...       18  \n",
      "after seq: [[499, 265, 55, 11, 500, 2, 388, 107], [501, 11, 16, 389, 6, 15, 108, 11, 145, 34, 146, 170, 502, 55, 11, 266, 2, 1, 503, 116, 48, 504, 2, 147, 505], [506, 117, 1, 45, 507, 1, 508, 3, 390], [509, 148, 3, 1, 26, 12, 91, 510, 109, 4, 75, 2, 8, 1, 267, 5, 215, 268], [511, 92, 73, 391, 1, 39, 56, 171, 15, 52, 108], [4, 392, 216, 15, 52, 56, 171, 5, 172, 27, 82, 217, 5, 511, 92, 73, 49, 9, 393], [1, 218, 219, 173, 18, 269, 13, 4, 270, 15, 145], [218, 219, 271, 272, 5, 1, 512, 3, 4, 174, 145, 5, 15, 108, 30, 513, 8, 6, 514, 18, 31, 269, 13, 4, 515, 17, 270, 394], [516, 1111, 220, 395, 30, 4, 1112, 5, 1, 517], [4, 1113, 220, 5, 516, 273, 27, 395, 30, 396, 5, 1, 517, 37, 397, 3, 221, 149, 1114, 1115, 93, 31, 398, 2, 147, 67], [221, 21, 94, 518, 91, 83, 84, 2, 54, 118, 95, 119, 6, 57, 519, 17, 150, 1, 45], [221, 21, 94, 84, 175, 2, 119, 91, 58, 68, 1, 40, 2, 120, 32, 121, 274, 3, 4, 118, 15, 54, 5, 520, 2, 521, 12, 272, 522, 523, 76, 176, 9, 222], [1116, 399], [223, 21, 44, 1117, 3, 57, 524, 525], [69, 3, 1, 224, 122, 21, 31, 5, 1, 1118, 225, 37, 59, 93, 5, 1, 400, 1119, 6, 149, 3, 1, 1120], [6, 37, 177, 45, 401, 1121, 1122, 1123, 21, 1124, 1125, 526], [22, 1, 56, 110, 35, 21, 96, 111, 1, 26, 123], [60, 402, 10, 226, 2, 97, 6, 227, 19, 85, 403], [70, 11, 48, 3, 1, 527], [528, 1, 529, 4, 1126, 1127, 5, 4, 1128, 1129], [1130, 1131, 528, 1, 529], [228, 1132, 44, 1133, 1, 530, 109, 4, 23, 1134, 9, 1, 1135, 10, 1136, 32, 40], [4, 1137, 1138, 36, 1139, 1140], [1141, 1142, 6, 1143, 275, 1144, 93, 1145, 1146, 2, 531, 57, 16, 4, 1147, 1148, 178, 5, 1149, 1150], [499, 265, 55, 11, 500, 2, 388, 107], [501, 11, 16, 389, 6, 15, 108, 11, 145, 34, 146, 170, 502, 55, 11, 266, 2, 1, 503, 116, 48, 504, 2, 147, 505], [179, 276, 532, 229, 8, 533, 2, 534, 15, 265], [1, 179, 535, 46, 536, 404, 17, 4, 537, 538, 148, 1, 539, 41, 405, 277, 2, 27, 82, 540, 2, 1, 180], [506, 117, 1, 45, 507, 1, 508, 3, 390], [509, 148, 3, 1, 26, 12, 91, 510, 109, 4, 75, 2, 8, 1, 267, 5, 215, 268], [1, 218, 219, 173, 18, 269, 13, 4, 270, 15, 145], [218, 219, 271, 272, 5, 1, 512, 3, 4, 174, 145, 5, 15, 108, 30, 513, 8, 6, 514, 18, 31, 269, 13, 4, 515, 17, 270, 394], [230, 5, 266, 9, 124, 5, 541, 271, 542, 406, 77], [1, 33, 231, 543, 3, 12, 544, 6, 69, 545, 546, 3, 4, 547, 93, 230, 407, 278, 548, 78, 1, 549, 550, 551, 49], [552, 24, 553, 13, 1, 554, 555], [408, 279, 12, 556, 4, 557, 558, 4, 559, 560, 61, 561, 57, 562, 6, 280, 178, 10, 74, 3, 38, 45], [221, 21, 94, 518, 91, 83, 84, 2, 54, 118, 95, 119, 6, 57, 519, 17, 150, 1, 45], [221, 21, 94, 84, 175, 2, 119, 91, 58, 68, 1, 40, 2, 120, 32, 121, 274, 3, 4, 118, 15, 54, 5, 520, 2, 521, 12, 272, 522, 523, 76, 176, 9, 222], [232, 172, 563, 1151, 24, 564, 233], [70, 22, 35, 281, 2, 125, 86, 1, 42, 565, 409], [24, 151, 233], [566, 1152, 87, 15, 62], [22, 1, 56, 110, 35, 21, 96, 111, 1, 26, 123], [60, 402, 10, 226, 2, 97, 6, 227, 19, 85, 403], [70, 11, 48, 3, 1, 527], [282, 126, 181, 5, 4, 567, 568, 569, 410, 5, 182], [1, 570, 283, 5, 411, 412, 1, 88, 3, 1, 26, 571, 38, 572, 573, 5, 1, 574, 3, 575, 2, 576, 2, 1, 577, 1, 578, 1, 284, 579, 6, 580], [581, 2, 582, 1, 583, 6, 584, 285, 585, 5, 71], [70, 4, 586, 3, 22, 2, 587, 5, 280, 6, 588, 5, 1, 33, 2, 152], [234, 1, 589, 590, 181, 591, 592, 593, 286], [7, 146, 3, 1, 287, 43, 127, 7, 1, 40, 594, 595, 1, 286, 11, 128, 596, 5, 1, 597, 3, 1, 6, 47, 598, 129, 599, 14, 69], [179, 276, 532, 229, 8, 533, 2, 534, 15, 265], [1, 179, 535, 46, 536, 404, 17, 4, 537, 538, 148, 1, 539, 41, 405, 277, 2, 27, 82, 540, 2, 1, 180], [230, 5, 266, 9, 124, 5, 541, 271, 542, 406, 77], [1, 33, 231, 543, 3, 12, 544, 6, 69, 545, 546, 3, 4, 547, 93, 230, 407, 278, 548, 78, 1, 549, 550, 551, 49], [9, 1, 600, 3, 413, 232, 98, 288, 25, 289, 414, 13, 19, 235, 601], [602, 1, 232, 98, 288, 21, 153, 603, 17, 1, 415, 183, 3, 235, 9, 151, 13, 184, 36, 20, 25, 6, 20, 72, 130, 131], [28, 132, 604, 1, 605, 3, 12, 72, 2, 606, 607, 3, 1, 98, 6, 608, 5, 1, 609, 3, 154, 25, 610, 416, 9, 417, 39, 73, 99, 46, 611, 612, 3, 613, 614], [552, 24, 553, 13, 1, 554, 555], [408, 279, 12, 556, 4, 557, 558, 4, 559, 560, 61, 561, 57, 562, 6, 280, 178, 10, 74, 3, 38, 45], [1, 615, 616, 1153, 1154, 1, 1155, 3, 1, 26], [1156, 418, 405, 290, 46, 563, 419, 291, 1157, 16, 617, 1158, 2, 402, 32, 618, 117, 6, 2, 420, 32, 1159, 6, 2, 1160, 32, 1161], [41, 8, 1, 40, 1162, 619, 16, 616], [1163, 2, 1164, 421, 71, 620], [287, 617, 292], [1, 293, 1165, 1166, 21, 31, 234, 5, 6, 150, 1167, 37, 1, 620, 621, 2, 422, 8, 177, 1, 26], [1168, 1169, 21, 1170, 423, 13, 622, 424, 4, 236, 1171], [12, 55, 73, 49, 1, 623, 29, 4, 1172, 2, 4, 1173, 623, 2, 123, 4, 1174, 3, 622, 36, 14, 1175, 1176, 10, 27, 63, 7, 19, 85, 133, 33], [79, 2, 185, 24, 5, 624, 625], [1, 626, 627, 107, 67, 2, 1, 628, 425, 6, 629, 3, 1, 236, 18, 134, 630, 3, 631, 10, 14, 27, 112, 421, 135, 36, 632, 633, 634], [635, 294, 636, 3, 637, 186, 136, 16], [154, 294, 237, 4, 638, 295, 100, 5, 639, 640, 5, 46, 641, 642, 68, 1, 643, 3, 4, 644, 3, 296, 186], [282, 126, 181, 5, 4, 567, 568, 569, 410, 5, 182], [1, 570, 283, 5, 411, 412, 1, 88, 3, 1, 26, 571, 38, 572, 573, 5, 1, 574, 3, 575, 2, 576, 2, 1, 577, 1, 578, 1, 284, 579, 6, 580], [1, 297, 43, 237, 298, 299, 187, 68, 12, 300], [645, 646, 1, 187, 647, 27, 648, 12, 300, 649, 2, 650, 298, 299, 651, 6, 121, 301], [22, 11, 59, 302, 5, 4, 426, 26, 6, 155, 11, 59, 302, 652, 16, 69], [581, 2, 582, 1, 583, 6, 584, 285, 585, 5, 71], [70, 4, 586, 3, 22, 2, 587, 5, 280, 6, 588, 5, 1, 33, 2, 152], [238, 45, 653, 64, 7, 71, 654, 5, 655], [656, 6, 657, 11, 188, 658, 659, 5, 1, 152, 33, 125, 10, 32, 660, 21, 31, 16, 1, 661, 3, 1, 15], [234, 1, 589, 590, 181, 591, 592, 593, 286], [7, 146, 3, 1, 287, 43, 127, 7, 1, 40, 594, 595, 1, 286, 11, 128, 596, 5, 1, 597, 3, 1, 6, 47, 598, 129, 599, 14, 69], [427, 428, 662, 429, 64, 7, 25, 2, 8, 2, 46, 430, 186, 95, 28, 50], [663, 20, 25, 27, 53, 49, 239, 41, 64, 2, 431, 30, 664, 1, 189, 89, 9, 113], [34, 432, 56, 220, 156, 433, 9, 303, 10, 41, 18, 53, 304, 101], [1177, 25, 157, 2, 427, 430, 1178, 665, 74, 3, 434], [432, 56, 220, 1179, 1180, 27, 666, 240, 4, 429, 64, 7, 1, 20, 2, 435, 1, 28, 50, 16, 46, 1181, 1182], [9, 1, 600, 3, 413, 232, 98, 288, 25, 289, 414, 13, 19, 235, 601], [602, 1, 232, 98, 288, 21, 153, 603, 17, 1, 415, 183, 3, 235, 9, 151, 13, 184, 36, 20, 25, 6, 20, 72, 130, 131], [28, 132, 604, 1, 605, 3, 12, 72, 2, 606, 607, 3, 1, 98, 6, 608, 5, 1, 609, 3, 154, 25, 610, 416, 9, 417, 39, 73, 99, 46, 611, 612, 3, 613, 614], [79, 2, 185, 24, 5, 624, 625], [1, 626, 627, 107, 67, 2, 1, 628, 425, 6, 629, 3, 1, 236, 18, 134, 630, 3, 631, 10, 14, 27, 112, 421, 135, 36, 632, 633, 634], [667, 305, 43, 668, 1, 669, 670, 5, 671, 136, 16], [672, 305, 306, 673, 7, 215, 135, 6, 180, 674, 241, 120, 5, 1, 236, 102, 137], [102, 136, 3, 190], [635, 294, 636, 3, 637, 186, 136, 16], [154, 294, 237, 4, 638, 295, 100, 5, 639, 640, 5, 46, 641, 642, 68, 1, 643, 3, 4, 644, 3, 296, 186], [51, 2, 137, 5, 71], [60, 114, 97, 2, 419, 65, 86, 1, 138, 10, 44, 675, 112, 6, 307, 191, 5, 4, 436, 33], [70, 3, 1, 19, 85, 676, 308, 60, 227, 2, 677, 65, 10, 1, 45, 192, 285], [1, 297, 43, 237, 298, 299, 187, 68, 12, 300], [645, 646, 1, 187, 647, 27, 648, 12, 300, 649, 2, 650, 298, 299, 651, 6, 121, 301], [22, 11, 59, 302, 5, 4, 426, 26, 6, 155, 11, 59, 302, 652, 16, 69], [238, 45, 653, 64, 7, 71, 654, 5, 655], [656, 6, 657, 11, 188, 658, 659, 5, 1, 152, 33, 125, 10, 32, 660, 21, 31, 16, 1, 661, 3, 1, 15], [89, 127, 5, 678, 4, 679, 309, 680, 13, 681, 682, 683], [37, 684, 685, 686, 32, 67, 193, 1, 194, 5, 309, 242, 11, 437], [34, 687, 688, 11, 103, 243, 689], [98, 690, 691, 18, 692, 195, 8, 2, 693], [1, 98, 29, 694, 5, 1, 139, 6, 9, 4, 58, 2, 104, 36, 438, 3, 20, 25, 48, 3, 695, 696, 697, 16, 698], [427, 428, 662, 429, 64, 7, 25, 2, 8, 2, 46, 430, 186, 95, 28, 50], [663, 20, 25, 27, 53, 49, 239, 41, 64, 2, 431, 30, 664, 1, 189, 89, 9, 113], [34, 432, 56, 220, 156, 433, 9, 303, 10, 41, 18, 53, 304, 101], [1183, 1184], [699, 21, 700, 28, 50, 195, 701, 21, 279, 14], [20, 1185, 701, 43, 18, 6, 140, 92, 702, 407, 1186, 27, 700, 1187, 50, 431, 410, 2, 1188], [51, 35, 703], [439, 3, 14, 310, 80, 3, 704, 1, 8, 705, 114, 97, 86, 311, 13, 440, 312, 2, 191], [4, 313, 314, 51], [4, 45, 706, 312, 81, 4, 707, 314, 708, 2, 12, 709, 310], [38, 33, 60, 114, 97, 2, 710, 32, 149, 711, 138], [667, 305, 43, 668, 1, 669, 670, 5, 671, 136, 16], [672, 305, 306, 673, 7, 215, 135, 6, 180, 674, 241, 120, 5, 1, 236, 102, 137], [102, 136, 3, 190], [47, 712, 58, 713, 15, 315], [12, 714, 715, 4, 716, 58, 17, 717, 2, 23, 718, 244, 719, 6, 121, 12, 720, 2, 316, 5, 317, 721], [51, 2, 137, 5, 71], [60, 114, 97, 2, 419, 65, 86, 1, 138, 10, 44, 675, 112, 6, 307, 191, 5, 4, 436, 33], [70, 3, 1, 19, 85, 676, 308, 60, 227, 2, 677, 65, 10, 1, 45, 192, 285], [224, 722, 140, 723, 30, 81, 157, 177, 1, 724], [48, 318, 3, 725, 44, 726, 158, 727, 30, 8, 74, 3, 1, 40, 9, 728, 396, 6, 245, 184, 111, 78, 93, 114, 2, 147, 67], [4, 176, 729, 133, 42, 5, 4, 100, 196, 35, 90, 109, 47], [319, 320, 730, 23, 731, 94, 246, 27, 732, 8, 321, 247, 121, 6, 100, 733, 734, 74, 7, 14, 735, 6, 27, 82, 226, 36, 736], [1, 248, 80, 197, 110, 60, 249, 38, 42], [737, 738, 739, 5, 322, 3, 198, 323, 740, 6, 19], [89, 127, 5, 678, 4, 679, 309, 680, 13, 681, 682, 683], [37, 684, 685, 686, 32, 67, 193, 1, 194, 5, 309, 242, 11, 437], [34, 687, 688, 11, 103, 243, 689], [98, 690, 691, 18, 692, 195, 8, 2, 693], [1, 98, 29, 694, 5, 1, 139, 6, 9, 4, 58, 2, 104, 36, 438, 3, 20, 25, 48, 3, 695, 696, 697, 16, 698], [51, 35, 703], [439, 3, 14, 310, 80, 3, 704, 1, 8, 705, 114, 97, 86, 311, 13, 440, 312, 2, 191], [4, 313, 314, 51], [4, 45, 706, 312, 81, 4, 707, 314, 708, 2, 12, 709, 310], [38, 33, 60, 114, 97, 2, 710, 32, 149, 711, 138], [47, 712, 58, 713, 15, 315], [12, 714, 715, 4, 716, 58, 17, 717, 2, 23, 718, 244, 719, 6, 121, 12, 720, 2, 316, 5, 317, 721], [224, 722, 140, 723, 30, 81, 157, 177, 1, 724], [48, 318, 3, 725, 44, 726, 158, 727, 30, 8, 74, 3, 1, 40, 9, 728, 396, 6, 245, 184, 111, 78, 93, 114, 2, 147, 67], [4, 176, 729, 133, 42, 5, 4, 100, 196, 35, 90, 109, 47], [319, 320, 730, 23, 731, 94, 246, 27, 732, 8, 321, 247, 121, 6, 100, 733, 734, 74, 7, 14, 735, 6, 27, 82, 226, 36, 736], [5, 741, 66, 742, 16, 324, 325, 326, 441, 31, 7, 311, 327], [1, 743, 107, 5, 12, 199, 2, 744, 240, 9, 328, 329, 3, 745, 746, 747, 748, 6, 250, 749, 64, 2, 750, 1, 242, 3, 751, 2, 170, 5, 14, 752, 324, 325], [330, 753, 39, 8, 141, 331, 200, 66, 754, 201, 435, 755], [4, 97, 756, 5, 77, 41, 200, 201, 148, 41, 200, 66, 68, 1, 39], [14, 4, 313, 332, 757, 71, 8, 758], [1, 248, 80, 197, 110, 60, 249, 38, 42], [737, 738, 739, 5, 322, 3, 198, 323, 740, 6, 19], [4, 1189, 43, 1190, 759, 442, 54, 333, 7, 190], [1191, 1192, 1193, 417, 3, 1194, 251, 10, 41, 227, 4, 333, 54, 443, 7, 1, 15, 9, 334, 444, 30, 41, 760, 1, 76, 1195, 5, 4, 761, 199, 2, 445, 762, 17, 1196, 446, 20, 72, 130, 131], [28, 132, 1197], [19, 39, 11, 391, 1, 392, 216, 142, 52], [1, 80, 3, 39, 2, 171, 1, 763, 23, 15, 52, 18, 328], [5, 741, 66, 742, 16, 324, 325, 326, 441, 31, 7, 311, 327], [1, 743, 107, 5, 12, 199, 2, 744, 240, 9, 328, 329, 3, 745, 746, 747, 748, 6, 250, 749, 64, 2, 750, 1, 242, 3, 751, 2, 170, 5, 14, 752, 324, 325], [330, 753, 39, 8, 141, 331, 200, 66, 754, 201, 435, 755], [4, 97, 756, 5, 77, 41, 200, 201, 148, 41, 200, 66, 68, 1, 39], [14, 4, 313, 332, 757, 71, 8, 758], [19, 39, 11, 391, 1, 392, 216, 142, 52], [1, 80, 3, 39, 2, 171, 1, 763, 23, 15, 52, 18, 328], [764, 765, 766, 181, 335, 767], [768, 2, 1, 769, 18, 4, 770, 134, 771, 13, 772, 773, 41, 774, 14, 5, 1, 447, 775], [23, 5, 776, 1198, 6, 1, 252, 3, 4, 1199], [448, 23, 776, 2, 1200, 74, 38, 42], [1, 1201, 1, 123, 3, 25, 61, 1, 123, 3, 55, 1202], [5, 1, 1203, 3, 1, 416, 9, 1, 115, 777, 1204, 778, 1205, 6, 777, 2, 188, 16, 22, 152, 159], [179, 143, 15, 62, 12, 779, 780], [77, 41, 21, 31, 62, 781, 159, 42, 276, 782, 1, 783, 2, 66, 1, 62, 37, 784], [253, 110, 4, 1206, 449, 13, 12, 1207], [14, 53, 450, 451, 526, 6, 336, 1208, 452, 32, 140], [70, 22, 25, 273, 318, 44, 49, 86, 1, 202, 3, 1, 115], [69, 3, 20, 25, 273, 1209, 1210, 1, 453, 454, 10, 202, 1, 115, 785, 9, 334], [48, 187, 2, 1, 20, 7, 1211, 1, 203, 6, 87, 273, 318, 395], [70, 22, 59, 49], [1, 1212, 329, 93, 1213, 34, 1, 455, 27, 4, 433, 1214, 2, 92], [1215, 1, 1216, 7, 1217, 1, 254, 3, 1218, 62, 6, 4, 762, 19, 337, 2, 786, 290], [79, 38, 138, 5, 787, 456, 14, 788], [789, 204, 790, 791, 205, 17, 1, 792, 3, 793, 401, 206, 207, 2, 14, 80, 3, 397, 794], [795, 124, 22, 2, 125, 86, 1, 796, 208], [1, 797, 10, 124, 452, 798, 29, 4, 33, 231, 799, 282, 1, 23, 457, 10, 800, 1, 418], [764, 765, 766, 181, 335, 767], [768, 2, 1, 769, 18, 4, 770, 134, 771, 13, 772, 773, 41, 774, 14, 5, 1, 447, 775], [255, 160, 338, 801, 61, 802, 16, 88, 3, 23, 223], [13, 1, 256, 337, 803, 1, 56, 291, 339, 7, 71, 804, 29, 805, 2, 234, 5, 1, 56, 255, 292, 3, 1, 33], [297, 13, 806, 807, 340, 13, 808, 809, 73, 77], [1, 458, 3, 810, 49, 9, 811, 10, 812, 813, 814, 132, 29, 47, 3, 78, 43, 341, 82, 340, 5, 342, 459, 30, 4, 453, 460, 25, 454, 202, 1, 115], [456, 4, 461], [252, 4, 815], [257, 228, 1219, 816, 5, 1220, 18, 524, 34, 462, 4, 1221, 16, 67, 90, 1222, 1, 817], [179, 143, 15, 62, 12, 779, 780], [77, 41, 21, 31, 62, 781, 159, 42, 276, 782, 1, 783, 2, 66, 1, 62, 37, 784], [818, 24, 26, 819], [88, 4, 23, 819, 18, 1223], [2, 252, 14, 1224, 621, 818, 12, 231, 47, 439, 785, 9, 820, 35, 816, 17, 26, 1225], [4, 1226, 1227], [1228, 564, 18, 279, 336], [90, 35, 1229, 22], [258, 53, 1230, 1231], [41, 156, 14], [34, 1, 26, 18, 1232, 122, 2, 103, 451, 329, 3, 619, 463], [821, 457, 161, 778, 80, 3, 28, 50, 1233], [1, 50, 822, 1234, 53, 1235, 79, 823, 14, 27, 824, 134, 825, 7, 1, 178, 246, 18, 2, 31, 1236, 240, 148, 3, 1, 26], [9, 464, 23, 343, 1, 826, 465, 827, 3, 344], [73, 49, 1, 828, 29, 12, 829, 2, 830, 831, 345, 17, 229, 9, 1, 832, 43, 140, 8, 141, 833, 1, 26], [4, 346, 834, 188, 16, 162], [835, 9, 4, 301, 836, 157, 259, 1, 163, 39, 4, 182, 837, 306, 12, 162, 838, 5, 839, 6, 4, 40, 9, 840], [79, 38, 138, 5, 787, 456, 14, 788], [789, 204, 790, 791, 205, 17, 1, 792, 3, 793, 401, 206, 207, 2, 14, 80, 3, 397, 794], [22, 11, 1, 51, 5, 1, 45, 10, 35, 137, 149], [22, 51, 841, 842, 61, 150, 1, 267, 843, 35, 112, 6, 307], [22, 164, 35, 844, 2, 1, 8, 845, 51, 2, 137, 5, 71], [795, 124, 22, 2, 125, 86, 1, 796, 208], [1, 797, 10, 124, 452, 798, 29, 4, 33, 231, 799, 282, 1, 23, 457, 10, 800, 1, 418], [260, 81, 846, 466, 99, 1237, 3, 1238, 1239, 5, 1240, 1241], [4, 1242, 257, 260, 77, 1, 158, 1243, 27, 1244, 4, 92, 847, 817, 5, 4, 40, 239, 1, 1245, 29, 846, 5, 1246, 34, 467, 451, 1247], [28, 64, 12, 50, 1248, 3, 1249, 5, 12, 178, 13, 848, 699, 6, 1250], [20, 72, 130, 131], [28, 132, 64, 2, 143, 9, 4, 1251, 204, 2, 152, 849, 16, 4, 182, 3, 235, 1252, 6, 4, 850, 26, 13, 12, 162, 163, 50, 76, 1253, 46, 50, 822, 251, 151], [1254, 11, 1, 78, 43, 136, 5, 1, 115, 347], [4, 406, 165, 29, 1255, 4, 1256, 29, 666, 6, 133, 57, 136, 177, 1, 1257], [255, 160, 338, 801, 61, 802, 16, 88, 3, 23, 223], [13, 1, 256, 337, 803, 1, 56, 291, 339, 7, 71, 804, 29, 805, 2, 234, 5, 1, 56, 255, 292, 3, 1, 33], [297, 13, 806, 807, 340, 13, 808, 809, 73, 77], [1, 458, 3, 810, 49, 9, 811, 10, 812, 813, 814, 132, 29, 47, 3, 78, 43, 341, 82, 340, 5, 342, 459, 30, 4, 453, 460, 25, 454, 202, 1, 115], [12, 851, 61, 852, 853, 3, 24, 854, 79, 2, 252, 855, 19, 348], [856, 8, 857, 9, 147, 5, 32, 468, 11, 109, 10, 22, 29, 858, 4, 296, 859, 90, 860, 31, 861], [79, 2, 185, 24, 5, 862, 863], [1, 864, 116, 865, 13, 189, 866, 295, 1, 867, 868, 869, 6, 870, 871, 10, 277, 2, 14, 51, 5, 872], [873, 101, 11, 75, 2, 874, 14, 875, 16, 67], [16, 104, 139, 6, 100, 349, 6, 876, 469], [877, 1, 113, 347, 5, 1, 65, 116, 1, 8, 350, 18, 81, 878, 2, 103, 247, 6, 57, 351], [65, 2, 94, 118, 142, 54, 17, 91, 83, 84], [95, 59, 119, 208, 2, 1, 65, 84, 21, 44, 2, 879, 274, 10, 59, 11, 53, 315, 61, 44, 206, 205], [9, 464, 23, 343, 1, 826, 465, 827, 3, 344], [73, 49, 1, 828, 29, 12, 829, 2, 830, 831, 345, 17, 229, 9, 1, 832, 43, 140, 8, 141, 833, 1, 26], [4, 346, 834, 188, 16, 162], [835, 9, 4, 301, 836, 157, 259, 1, 163, 39, 4, 182, 837, 306, 12, 162, 838, 5, 839, 6, 4, 40, 9, 840], [166, 470, 205, 17, 352, 208, 124], [1, 880, 3, 1, 134, 143, 198, 461, 21, 330, 73, 881, 155, 882, 83, 58, 353, 68, 1, 883, 884, 9, 885], [50, 76, 886, 99, 322], [1, 887, 3, 165, 888, 31, 889, 16, 48, 890, 891, 4, 892, 398], [209, 471, 893, 339, 894, 895, 896, 897, 898, 400, 258, 899, 900, 472, 8, 138], [47, 225, 278, 224, 122, 6, 4, 901, 3, 8], [1, 399, 23, 902, 225, 21, 903, 1, 904, 448, 905, 354, 906, 6, 907, 6, 1, 908, 3, 909], [34, 910, 209, 94, 911, 40, 157], [22, 11, 1, 51, 5, 1, 45, 10, 35, 137, 149], [22, 51, 841, 842, 61, 150, 1, 267, 843, 35, 112, 6, 307], [22, 164, 35, 844, 2, 1, 8, 845, 51, 2, 137, 5, 71], [12, 851, 61, 852, 853, 3, 24, 854, 79, 2, 252, 855, 19, 348], [856, 8, 857, 9, 147, 5, 32, 468, 11, 109, 10, 22, 29, 858, 4, 296, 859, 90, 860, 31, 861], [79, 2, 185, 24, 5, 862, 863], [1, 864, 116, 865, 13, 189, 866, 295, 1, 867, 868, 869, 6, 870, 871, 10, 277, 2, 14, 51, 5, 872], [873, 101, 11, 75, 2, 874, 14, 875, 16, 67], [16, 104, 139, 6, 100, 349, 6, 876, 469], [877, 1, 113, 347, 5, 1, 65, 116, 1, 8, 350, 18, 81, 878, 2, 103, 247, 6, 57, 351], [65, 2, 94, 118, 142, 54, 17, 91, 83, 84], [95, 59, 119, 208, 2, 1, 65, 84, 21, 44, 2, 879, 274, 10, 59, 11, 53, 315, 61, 44, 206, 205], [89, 127, 5, 355, 4, 912, 913, 914, 13, 915, 916], [1, 26, 917, 4, 918, 2, 355, 89, 194, 34, 206, 166, 308, 101, 11, 192, 919, 920, 2, 31, 156, 101], [166, 470, 205, 17, 352, 208, 124], [1, 880, 3, 1, 134, 143, 198, 461, 21, 330, 73, 881, 155, 882, 83, 58, 353, 68, 1, 883, 884, 9, 885], [75, 2, 96, 19, 13, 24, 921, 356], [196, 35, 11, 192, 922, 24, 923, 356, 327, 7, 924, 6, 473, 357, 24, 925, 420, 14, 926], [50, 76, 886, 99, 322], [1, 887, 3, 165, 888, 31, 889, 16, 48, 890, 891, 4, 892, 398], [209, 471, 893, 339, 894, 895, 896, 897, 898, 400, 258, 899, 900, 472, 8, 138], [47, 225, 278, 224, 122, 6, 4, 901, 3, 8], [1, 399, 23, 902, 225, 21, 903, 1, 904, 448, 905, 354, 906, 6, 907, 6, 1, 908, 3, 909], [34, 910, 209, 94, 911, 40, 157], [358, 21, 359, 6, 210, 69, 104, 173, 360, 7, 159, 42], [358, 47, 3, 1, 927, 160, 5, 1, 474, 361, 362, 194, 21, 359, 69, 360, 156, 5, 1, 104, 173, 159, 42, 6, 210, 23, 362, 1, 161, 251, 9, 334], [8, 61, 475, 2, 1, 65, 363, 2, 81, 4, 15, 54], [261, 113, 91, 8, 434, 7, 1, 163, 39, 928, 120, 118, 15, 54, 443, 95, 119, 32, 58], [70, 22, 35, 281, 2, 125], [51, 2, 184, 17, 24, 929], [53, 930, 22, 2, 96, 13, 931, 253, 444, 16, 67], [462, 1, 932, 3, 253, 51, 6, 933, 167, 185, 24, 101], [89, 127, 5, 355, 4, 912, 913, 914, 13, 915, 916], [1, 26, 917, 4, 918, 2, 355, 89, 194, 34, 206, 166, 308, 101, 11, 192, 919, 920, 2, 31, 156, 101], [75, 2, 96, 19, 13, 24, 921, 356], [196, 35, 11, 192, 922, 24, 923, 356, 327, 7, 924, 6, 473, 357, 24, 925, 420, 14, 926], [1, 248, 80, 197, 110, 60, 249, 38, 42], [934, 935, 23, 936, 36, 937, 938, 6, 19], [1, 939, 144, 8, 17, 364, 162, 6, 365, 940, 941, 86, 4, 942, 52], [172, 49, 9, 393, 10, 14, 164, 144, 222, 17, 364, 55, 40, 6, 365, 99, 943, 3, 4, 15, 52, 217, 5, 105], [111, 35, 90, 8, 944, 70, 4, 75, 2, 103, 24, 945, 351], [4, 946, 947, 4, 108, 2, 103, 948, 17, 31, 949, 5, 317], [358, 21, 359, 6, 210, 69, 104, 173, 360, 7, 159, 42], [358, 47, 3, 1, 927, 160, 5, 1, 474, 361, 362, 194, 21, 359, 69, 360, 156, 5, 1, 104, 173, 159, 42, 6, 210, 23, 362, 1, 161, 251, 9, 334], [258, 468, 7, 1, 615], [223], [14, 4, 702], [15, 108, 6, 293, 366, 11, 1258, 117, 476, 85, 4, 168, 68, 1, 223], [1, 1259, 18, 237, 2, 1260, 665, 193, 6, 9, 1, 459, 34, 10, 326, 53, 31, 1261], [198, 238, 414], [16, 1, 1262, 815, 1, 1263, 1264, 3, 1, 1265, 477, 478, 1266, 1267, 1268, 5, 1, 1269], [8, 61, 475, 2, 1, 65, 363, 2, 81, 4, 15, 54], [261, 113, 91, 8, 434, 7, 1, 163, 39, 928, 120, 118, 15, 54, 443, 95, 119, 32, 58], [70, 22, 35, 281, 2, 125], [950, 37, 4, 62, 951], [139, 37, 54, 952], [1, 8, 350, 953, 5], [174, 36, 1, 26, 146, 8, 161, 44, 479, 367, 3, 12, 207, 954, 955, 199], [51, 2, 184, 17, 24, 929], [53, 930, 22, 2, 96, 13, 931, 253, 444, 16, 67], [462, 1, 932, 3, 253, 51, 6, 933, 167, 185, 24, 101], [480, 39, 11, 956, 128, 957], [22, 958, 2, 96, 34, 959], [256, 11, 140, 4, 960, 961, 3, 423, 141, 10, 481, 74, 482, 1, 15, 6, 962, 345], [4, 23, 207, 244, 4, 963, 196, 964, 965, 9, 1, 39, 3, 966], [1, 248, 80, 197, 110, 60, 249, 38, 42], [934, 935, 23, 936, 36, 937, 938, 6, 19], [1, 939, 144, 8, 17, 364, 162, 6, 365, 940, 941, 86, 4, 942, 52], [172, 49, 9, 393, 10, 14, 164, 144, 222, 17, 364, 55, 40, 6, 365, 99, 943, 3, 4, 15, 52, 217, 5, 105], [111, 35, 90, 8, 944, 70, 4, 75, 2, 103, 24, 945, 351], [4, 946, 947, 4, 108, 2, 103, 948, 17, 31, 949, 5, 317], [262, 7, 967, 169, 368, 968], [250, 366, 1, 368, 293, 7, 47, 33, 63, 969], [970, 4, 33, 971, 254, 11, 66, 972], [107, 973], [22, 409, 974, 38, 357, 112, 7, 35], [30, 4, 483, 484, 59, 8, 2, 1, 57, 975, 3, 1, 45], [275, 976, 4, 158, 977, 165, 29, 9, 4, 87, 168, 978, 5, 23, 979, 111, 41, 980, 981, 982], [102, 983, 984, 10, 32, 485, 129, 63], [950, 37, 4, 62, 951], [139, 37, 54, 952], [1, 8, 350, 953, 5], [174, 36, 1, 26, 146, 8, 161, 44, 479, 367, 3, 12, 207, 954, 955, 199], [480, 39, 11, 956, 128, 957], [22, 958, 2, 96, 34, 959], [256, 11, 140, 4, 960, 961, 3, 423, 141, 10, 481, 74, 482, 1, 15, 6, 962, 345], [4, 23, 207, 244, 4, 963, 196, 964, 965, 9, 1, 39, 3, 966], [262, 7, 967, 169, 368, 968], [250, 366, 1, 368, 293, 7, 47, 33, 63, 969], [970, 4, 33, 971, 254, 11, 66, 972], [107, 973], [22, 409, 974, 38, 357, 112, 7, 35], [30, 4, 483, 484, 59, 8, 2, 1, 57, 975, 3, 1, 45], [275, 976, 4, 158, 977, 165, 29, 9, 4, 87, 168, 978, 5, 23, 979, 111, 41, 980, 981, 982], [102, 983, 984, 10, 32, 485, 129, 63], [4, 166, 1270, 1271, 1272, 2, 4, 1273, 1274], [1275, 1276, 6, 275, 1277, 341, 4, 56, 484, 16, 4, 1278, 1279, 1280, 32, 1281, 16, 4, 1282, 1283], [412, 985, 4, 1284, 1285, 32, 485, 986, 36, 986], [1286, 1, 1287, 3, 24, 1288], [134, 823, 3, 332, 29, 86, 88, 17, 1289, 34, 1290, 1291, 262, 60, 90, 103, 229, 486, 820, 5, 1, 23, 33], [1292, 1293, 1294, 4, 1295, 394, 1296, 218, 219], [436, 425, 4, 1297, 112, 987, 3, 1, 988, 6, 7, 1, 988, 18, 152, 17, 1, 260, 1298, 117], [1299, 24, 1300, 68, 478], [24, 16, 67, 69, 1, 182, 155, 53, 1301, 79, 35, 1302, 24, 472, 110], [40, 11, 211, 7, 1, 989, 3, 19, 216, 142, 52], [990, 1, 52, 217, 5, 172, 16, 369, 133, 57, 991, 52, 11, 370, 476, 992, 47, 171, 5, 993, 994, 6, 87, 5, 105], [22, 2, 486, 38, 42], [995, 996, 997, 189, 998, 999, 1000, 13, 1001, 6, 1002, 1003, 1004, 36, 75, 3, 24, 268], [37, 28, 175, 2, 1005, 88, 46, 361, 487, 1006, 211, 7, 371, 203], [13, 1, 50, 3, 20, 72, 130, 131], [28, 450, 133, 76, 463, 12, 83, 3, 349, 1007, 99, 104, 6, 39, 116, 259, 1, 40, 37, 59, 211, 7, 1, 371, 3, 19, 203, 30, 257, 1008, 1009, 202, 1, 115, 38, 168, 5, 4, 1010, 2, 445, 20, 25, 488, 17, 31, 446], [1011, 128, 4, 1012], [1013, 1014, 66, 150], [40, 11, 211, 7, 1, 989, 3, 19, 216, 142, 52], [990, 1, 52, 217, 5, 172, 16, 369, 133, 57, 991, 52, 11, 370, 476, 992, 47, 171, 5, 993, 994, 6, 87, 5, 105], [95, 1, 115, 347, 143, 7, 1303, 6, 241, 3, 1304], [4, 1305, 3, 825, 257, 1306, 259, 1, 40, 760, 42, 250, 6, 824, 489, 7, 4, 1307, 466, 2, 1308, 20, 25, 72, 488], [13, 333, 54, 480, 169, 3, 460, 255, 27, 4, 1309, 88], [30, 48, 84, 9, 1310, 58, 54, 333, 7, 1, 15, 160, 21, 53, 31, 1311, 2, 530, 7, 87, 42], [28, 175, 473, 88, 13, 263, 466, 6, 1312, 1313], [5, 12, 199, 2, 1314, 4, 1315, 490, 17, 1, 25, 525, 1, 20, 72, 64, 2, 491, 74, 492, 3, 263, 106, 5, 46, 56, 76, 9, 565, 3, 4, 291, 786, 64, 6, 12, 1316, 493, 471], [24, 151, 233], [28, 363, 2, 212, 25, 372], [566, 261, 1317, 14, 1318, 78, 88, 13, 92, 847, 247], [1, 62, 1319, 18, 1320, 5, 4, 40, 13, 19, 85, 15, 1321, 1, 45, 447, 415, 1322], [1323, 43, 1015, 319, 320, 222, 5, 65, 175, 1016], [1, 197, 287, 1015, 36, 1324, 2, 464, 5, 1325, 441, 30, 344, 1326, 319, 320, 494, 204, 469, 487], [38, 42, 59, 264, 5, 23, 1327], [109, 4, 1017, 7, 1018, 201, 5, 1019, 1020], [1, 494, 1021, 1022, 1023, 495, 289, 1, 254, 37, 96, 1, 1024, 1025], [34, 1, 1026, 11, 1027, 1028], [28, 64, 2, 491, 74, 492, 3, 263, 106, 5, 46, 56, 76, 37, 20], [20, 72, 373, 28, 122, 27, 1029, 4, 1030, 3, 1031, 10, 41, 90, 374, 30, 1, 50, 2, 261, 212, 48, 3, 20, 25, 372], [22, 2, 486, 38, 42], [995, 996, 997, 189, 998, 999, 1000, 13, 1001, 6, 1002, 1003, 1004, 36, 75, 3, 24, 268], [37, 28, 175, 2, 1005, 88, 46, 361, 487, 1006, 211, 7, 371, 203], [13, 1, 50, 3, 20, 72, 130, 131], [28, 450, 133, 76, 463, 12, 83, 3, 349, 1007, 99, 104, 6, 39, 116, 259, 1, 40, 37, 59, 211, 7, 1, 371, 3, 19, 203, 30, 257, 1008, 1009, 202, 1, 115, 38, 168, 5, 4, 1010, 2, 445, 20, 25, 488, 17, 31, 446], [1011, 128, 4, 1012], [1013, 1014, 66, 150], [190, 403, 29, 4, 426, 1328, 3, 1329, 43, 1330, 1331, 77], [12, 1332, 1333, 18, 482, 4, 1334, 1335, 3, 850, 1336, 6, 12, 1032, 1337, 7, 1338, 60, 44, 761, 5, 1339, 478, 389], [24, 167, 233, 50, 6, 263, 106], [70, 22, 35, 281, 2, 125, 16, 1, 123, 3, 1, 76], [1340, 241, 62, 240], [228, 105, 27, 1341, 483, 1342], [1, 40, 18, 1343, 4, 243, 7, 14, 428, 437, 1344, 3, 15, 62, 1032, 9], [10, 1345, 326, 1346, 105, 1347, 2, 1348, 1349, 52, 37, 108, 145], [149, 821, 455, 11, 465], [53, 344], [1, 1350, 455, 1351, 1352, 63, 33, 1, 40, 204, 1353, 3, 1354, 251, 9, 151, 5, 1355], [24, 151, 233], [28, 363, 2, 212, 25, 372], [155, 213, 126, 18, 153, 375, 167, 5, 4, 26], [1, 15, 26, 27, 174, 213, 126, 34, 1033, 117, 1034, 467, 7, 348, 1035, 5, 170, 264], [109, 4, 1017, 7, 1018, 201, 5, 1019, 1020], [1, 494, 1021, 1022, 1023, 495, 289, 1, 254, 37, 96, 1, 1024, 1025], [34, 1, 1026, 11, 1027, 1028], [25, 106, 376, 3, 142, 8, 144, 34, 28, 377, 1036, 2, 210, 378], [1, 20, 1037, 246, 164, 53, 81, 1038, 1039, 113, 30, 373, 28, 1040, 165, 29, 367, 3, 4, 1041, 3, 106, 10, 154, 28, 18, 128, 2, 212], [25, 376, 15, 8, 141, 17, 379, 6, 105, 28, 122, 77, 14, 1042, 63], [20, 25, 106, 12, 123, 2, 1, 144, 9, 8, 17, 379, 6, 105, 2, 1, 163, 39, 4, 378, 10, 29, 1043, 1044, 36, 377, 2, 20, 72, 130, 131], [28, 132], [380, 43, 29, 1045, 7, 490, 176, 5, 1046, 1047], [1048, 1049, 12, 55, 1050, 380, 29, 1051, 63, 42, 30, 290, 19, 85, 4, 168, 1052, 1053], [102, 49, 331, 1054, 14], [4, 381, 135, 120, 1, 1055, 1056, 3, 8], [1, 381, 1057, 1058, 449, 33, 3, 284, 1059, 5, 4, 23, 477, 135, 13, 1060, 1, 1061, 354, 65], [1062, 1063, 2, 32, 382, 183, 5, 87, 383, 63, 169, 37, 83, 8, 353], [1, 1064, 243, 7, 4, 47, 75, 321, 58, 283, 2, 63, 169, 14, 382, 183, 5, 16, 369, 87, 383, 384, 2, 1065, 3, 342, 166], [1066, 338, 190, 343, 2, 1067, 78, 13, 48, 1068, 8, 19, 1069], [1, 1070, 158, 18, 1071, 374, 15, 92, 442, 10, 129, 424, 8, 6, 1072, 7, 78, 43, 44, 82, 62, 61, 43, 44, 1073, 17, 335, 1, 1074, 195, 1075, 422, 1, 1076, 3, 57, 12, 496, 10, 27, 209, 82, 1077, 5, 1, 385, 1078, 6, 36, 1079, 161], [213, 126, 18, 153, 375, 167, 5, 4, 26], [1, 15, 26, 27, 1080, 214, 3, 55, 68, 1081, 6, 1082, 19, 85, 214, 3, 191, 3, 32, 92, 1083, 384, 2, 4, 316, 36, 245, 1084, 4, 1085, 1086, 1087, 260], [28, 64, 2, 491, 74, 492, 3, 263, 106, 5, 46, 56, 76, 37, 20], [20, 72, 373, 28, 122, 27, 1029, 4, 1030, 3, 1031, 10, 41, 90, 374, 30, 1, 50, 2, 261, 212, 48, 3, 20, 25, 372], [155, 213, 126, 18, 153, 375, 167, 5, 4, 26], [1, 15, 26, 27, 174, 213, 126, 34, 1033, 117, 1034, 467, 7, 348, 1035, 5, 170, 264], [25, 106, 376, 3, 142, 8, 144, 34, 28, 377, 1036, 2, 210, 378], [1, 20, 1037, 246, 164, 53, 81, 1038, 1039, 113, 30, 373, 28, 1040, 165, 29, 367, 3, 4, 1041, 3, 106, 10, 154, 28, 18, 128, 2, 212], [25, 376, 15, 8, 141, 17, 379, 6, 105, 28, 122, 77, 14, 1042, 63], [20, 25, 106, 12, 123, 2, 1, 144, 9, 8, 17, 379, 6, 105, 2, 1, 163, 39, 4, 378, 10, 29, 1043, 1044, 36, 377, 2, 20, 72, 130, 131], [28, 132], [55, 386, 387, 17, 1088, 30, 143, 14, 323, 1089], [352, 493, 73, 497, 1, 386, 1090, 303, 6, 49, 102, 29, 31, 387, 7, 370, 1091, 10, 129, 1092, 1, 180], [380, 43, 29, 1045, 7, 490, 176, 5, 1046, 1047], [1048, 1049, 12, 55, 1050, 380, 29, 1051, 63, 42, 30, 290, 19, 85, 4, 168, 1052, 1053], [102, 49, 331, 1054, 14], [89, 127, 5, 1093, 4, 1094, 1095, 9, 1096, 1097, 7, 214], [30, 66, 1098, 5, 1099, 1100, 38, 1101, 193, 1, 1102, 1103, 3, 1104, 18, 1105, 2, 304, 19, 385, 5, 1106, 3, 336, 23], [4, 381, 135, 120, 1, 1055, 1056, 3, 8], [1, 381, 1057, 1058, 449, 33, 3, 284, 1059, 5, 4, 23, 477, 135, 13, 1060, 1, 1061, 354, 65], [1062, 1063, 2, 32, 382, 183, 5, 87, 383, 63, 169, 37, 83, 8, 353], [1, 1064, 243, 7, 4, 47, 75, 321, 58, 283, 2, 63, 169, 14, 382, 183, 5, 16, 369, 87, 383, 384, 2, 1065, 3, 342, 166], [1066, 338, 190, 343, 2, 1067, 78, 13, 48, 1068, 8, 19, 1069], [1, 1070, 158, 18, 1071, 374, 15, 92, 442, 10, 129, 424, 8, 6, 1072, 7, 78, 43, 44, 82, 62, 61, 43, 44, 1073, 17, 335, 1, 1074, 195, 1075, 422, 1, 1076, 3, 57, 12, 496, 10, 27, 209, 82, 1077, 5, 1, 385, 1078, 6, 36, 1079, 161], [213, 126, 18, 153, 375, 167, 5, 4, 26], [1, 15, 26, 27, 1080, 214, 3, 55, 68, 1081, 6, 1082, 19, 85, 214, 3, 191, 3, 32, 92, 1083, 384, 2, 4, 316, 36, 245, 1084, 4, 1085, 1086, 1087, 260], [8, 13, 4, 1356, 7, 48, 14, 4, 71, 1357], [1, 1358, 3, 332, 1359, 1, 26, 6, 203, 759, 198, 55, 44, 1360, 146, 8, 2, 1361, 79, 6, 239, 2, 8], [1362, 1363, 1364, 18, 38, 67, 1365, 187], [1, 89, 239, 215, 1366, 6, 1367, 93, 1368, 230, 13, 4, 1369, 153, 1370, 3, 411, 4, 33], [228, 14, 7, 242], [55, 386, 387, 17, 1088, 30, 143, 14, 323, 1089], [352, 493, 73, 497, 1, 386, 1090, 303, 6, 49, 102, 29, 31, 387, 7, 370, 1091, 10, 129, 1092, 1, 180], [89, 127, 5, 1093, 4, 1094, 1095, 9, 1096, 1097, 7, 214], [30, 66, 1098, 5, 1099, 1100, 38, 1101, 193, 1, 1102, 1103, 3, 1104, 18, 1105, 2, 304, 19, 385, 5, 1106, 3, 336, 23], [481, 117, 5, 4, 100, 7, 4, 33, 985, 4, 1371, 390, 3, 1372], [1016, 1373, 497, 5, 256, 100, 1374, 3, 1375, 6, 495, 1376, 83, 341, 258, 496, 79, 346, 32, 1377, 164, 63], [7, 48, 14, 228, 99], [1, 248, 80, 197, 110, 60, 249, 38, 42], [408, 95, 1378, 1379, 36, 1380, 1381, 1382, 4, 1383, 6, 1384, 5, 388, 107, 6, 19], [12, 1107, 139, 21, 1385, 15, 1108, 3, 69, 1386, 84], [1387, 1107, 139, 21, 114, 4, 618, 3, 474, 1108, 226, 6, 81, 1, 1388, 3, 531, 458, 84], [413, 1389, 1109, 498, 1390, 264, 3, 262, 6, 1110, 2, 337, 1, 50, 440], [111, 20, 1391, 848, 1392, 46, 1393, 404, 2, 1, 204, 9, 113, 1394, 41, 1395, 193, 1, 1396, 2, 4, 470, 3, 1109, 498, 264, 3, 262, 6, 1110, 987, 46, 245, 195, 154, 498, 1397, 3, 244, 1398, 438, 7, 46, 1399, 1400, 6, 3, 1, 1401, 3, 8, 849, 1402, 4, 1403, 1404], [7, 1405, 1406, 489, 241], [1407, 44, 346, 1408, 160, 2, 1409, 5, 292, 34, 10, 489, 27, 479, 19, 1410, 2, 66, 160, 2, 8, 177, 1, 26], [238, 1411, 1412, 1413, 3, 1, 1414, 33, 18, 366], [1415, 93, 188, 2, 1, 178, 37, 4, 1416, 7, 4, 475, 2, 1417, 5, 1, 238, 45]]\n",
      "total_word: 6804\n",
      "word_count: 1417\n"
     ]
    }
   ],
   "source": [
    "# preprocess data, including stemming, tokenizing for model\n",
    "df_file = pd.read_csv('NYTimes_200.csv') \n",
    "\n",
    "col = ['s_id', 'original_sent', 'stemmed_sent', 'num_word']\n",
    "df_weight = pd.DataFrame(columns = col)\n",
    "sen_list = []\n",
    "unst_sen_list = []\n",
    "\n",
    "df_weight, sen_list, unst_sen_list = preprocess(df_file, df_weight, sen_list, unst_sen_list)\n",
    "print(df_weight.tail())\n",
    "\n",
    "token = Tokenizer() \n",
    "token.fit_on_texts(sen_list) \n",
    "seq = token.texts_to_sequences(sen_list)\n",
    "print('after seq:', seq)\n",
    "total_word = sum(len(w) for w in seq) # sum of words\n",
    "print('total_word:', total_word)\n",
    "word_count = len(token.word_index) # sum of distinct words\n",
    "print('word_count:', word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5724a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbow_model(seq, window_size, total_word):\n",
    "    total_length = window_size*2\n",
    "    for text in seq:\n",
    "        text_len = len(text)\n",
    "        for idx, word in enumerate(text):\n",
    "            context_word = []\n",
    "            target   = []            \n",
    "            begin = idx - window_size\n",
    "            end = idx + window_size + 1\n",
    "            context_word.append([text[i] for i in range(begin, end) if 0 <= i < text_len and i != idx])\n",
    "            target.append(word)\n",
    "            # print('context_word:', context_word, '\\ntarget:', target)\n",
    "            contextual = sequence.pad_sequences(context_word, maxlen=total_length)\n",
    "            # print('contextual:', contextual)\n",
    "            final_target = np_utils.to_categorical(target, total_word)\n",
    "            # print('final_target:', final_target)\n",
    "            yield(contextual, final_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11048509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(seq, total_word, window_size, epoch):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=total_word, output_dim=100, input_length=window_size*2))\n",
    "    model.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(100,)))\n",
    "    model.add(Dense(total_word, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    for i in range(epoch):\n",
    "        # timer\n",
    "        start = time.time()\n",
    "        loss = 0\n",
    "        for x, y in cbow_model(seq, window_size, total_word):\n",
    "            loss += model.train_on_batch(x, y)\n",
    "        print(i, loss)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('epoch:', i, 'takes time:', end - start)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b6d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50729.89162158966\n",
      "epoch: 0 takes time: 69.67118692398071\n",
      "1 40411.339516460896\n",
      "epoch: 1 takes time: 69.31519651412964\n",
      "2 36257.94778418541\n",
      "epoch: 2 takes time: 69.22339510917664\n",
      "3 31400.5911808908\n",
      "epoch: 3 takes time: 67.86318898200989\n",
      "4 26490.209703564644\n",
      "epoch: 4 takes time: 69.08726477622986\n",
      "5 21954.890511725098\n",
      "epoch: 5 takes time: 69.91128540039062\n",
      "6 17954.72737303935\n",
      "epoch: 6 takes time: 67.49894571304321\n",
      "7 14499.854848544579\n",
      "epoch: 7 takes time: 69.0541512966156\n"
     ]
    }
   ],
   "source": [
    "window_size = 3\n",
    "model = train_model(seq, total_word, window_size, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ea7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: win02_model_travel.bin\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('win02_model_travel.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60cfca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()[0]\n",
    "list_sw = stopwords.words('english')\n",
    "# list_sw = list_sw + ['’','—', '“', '”', '‘']\n",
    "\n",
    "list_text = []\n",
    "list_weight = []\n",
    "\n",
    "for text, i in token.word_index.items():\n",
    "    \n",
    "    if text in list_sw:\n",
    "        # print('remove', i, text)\n",
    "        # pass\n",
    "        continue\n",
    "    \n",
    "    list_text.append(text)\n",
    "    list_weight.append((weights[i]))\n",
    "        \n",
    "list_weight = np.array(list_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421e8970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word                                     3d\n",
      "1322  centerpiec  [0.30827895, -0.43908545, 0.29263514]\n",
      "1323       trade  [-0.3004399, 0.16807397, 0.024923302]\n",
      "1324      dealer  [-0.67597497, -0.7331393, -0.2187654]\n",
      "1325    bellweth    [-1.2260638, 0.22698018, 0.5379685]\n",
      "1326      normal   [-1.5819566, 0.15461136, 0.30871683]\n"
     ]
    }
   ],
   "source": [
    "# fit a 3d PCA model to the vectors\n",
    "pca = PCA(n_components=3)\n",
    "result = pca.fit_transform(list_weight)\n",
    "\n",
    "df_3d = pd.DataFrame(columns = ['word', '3d'])\n",
    "for i, r in enumerate(result):\n",
    "    df_3d.loc[len(df_3d)] = [list_text[i], r]\n",
    "\n",
    "print(df_3d.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d057609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_file_3 = open('3d_vectors_travel.txt' ,'w')\n",
    "vect_file_3.write('{} {}\\n'.format(len(list_text), 3))\n",
    "\n",
    "for i, word in enumerate(list_text):\n",
    "\n",
    "    final_vec_3 = ' '.join(map(str, list(result[i, :])))\n",
    "    vect_file_3.write('{} {}\\n'.format(word, final_vec_3))\n",
    "    \n",
    "vect_file_3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187cf932",
   "metadata": {},
   "source": [
    "# Sklearn TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e31af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9  ...  467  468  469  470  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   471  472  473  474  475   word  \n",
      "0  0.0  0.0  0.0  0.0  0.0  1920s  \n",
      "1  0.0  0.0  0.0  0.0  0.0  1930s  \n",
      "2  0.0  0.0  0.0  0.0  0.0   1977  \n",
      "3  0.0  0.0  0.0  0.0  0.0   19th  \n",
      "4  0.0  0.0  0.0  0.0  0.0   2000  \n",
      "\n",
      "[5 rows x 477 columns]\n"
     ]
    }
   ],
   "source": [
    "# sklearn uses (by default)\n",
    "# tf(t) = No. of times term ‘t’ occurs in a document\n",
    "# idf(t) = log e [ (1+n) / ( 1 + df(t) ) ] + 1 (default i:e smooth_idf = True)\n",
    "# In Scikit-learn ,The log is not base 10 , though it is the natural logarithm (which has a base e, e is an irrational and transcendental number approximately equal to 2.718)\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "vectors = vectorizer.fit_transform(unst_sen_list)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "df_temp = pd.DataFrame(vectors.T.todense()) #為了計算各word的weight加總，轉置\n",
    "df_temp['word'] = feature_names\n",
    "print (df_temp.head())\n",
    "\n",
    "w_list = []\n",
    "term_list = []\n",
    "for i in range(len(df_temp)):\n",
    "    w = 0\n",
    "    if df_temp.iloc[i,476] in list_sw:\n",
    "        # print('remove', i, text)\n",
    "        continue\n",
    "        \n",
    "    for j in range(len(df_temp.columns)-1):\n",
    "        w +=  df_temp.iloc[i,j]\n",
    "    \n",
    "    term_list.append(df_temp.iloc[i,476])\n",
    "    w_list.append(w)\n",
    "\n",
    "df_temp = pd.DataFrame(term_list, columns=['word'])\n",
    "df_temp['weight'] = w_list\n",
    "# df_temp = df_temp[['word', 'weight']]\n",
    "df_temp = df_temp.sort_values('weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c9e10af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15691360584736375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_tfidf.iloc[471,5] + df_tfidf.iloc[len(df_tfidf)-1,len(df_tfidf.columns)-1]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8bfc4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1652"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tfidf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb92d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_list = []\n",
    "\n",
    "for i in range(len(df_tfidf)):\n",
    "    w = 0\n",
    "    for j in range(len(df_tfidf.columns)):\n",
    "        w +=  df_tfidf.iloc[i,j]\n",
    "    \n",
    "    tfidf_list.append(w)\n",
    "\n",
    "# print(tfidf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3f95cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_id</th>\n",
       "      <th>original_sent</th>\n",
       "      <th>stemmed_sent</th>\n",
       "      <th>num_word</th>\n",
       "      <th>skl_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>472</td>\n",
       "      <td>When President Barack Obama gave his farewell ...</td>\n",
       "      <td>[when, presid, barack, obama, gave, hi, farewe...</td>\n",
       "      <td>56</td>\n",
       "      <td>6.414338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>473</td>\n",
       "      <td>For Elite Golfers, Money Talks</td>\n",
       "      <td>[for, elit, golfer, money, talk]</td>\n",
       "      <td>5</td>\n",
       "      <td>2.172869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>474</td>\n",
       "      <td>Sponsors have long paid players to compete in ...</td>\n",
       "      <td>[sponsor, have, long, paid, player, to, compet...</td>\n",
       "      <td>24</td>\n",
       "      <td>4.296807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>475</td>\n",
       "      <td>Art Basel, Swiss Centerpiece of the Trade’s Ye...</td>\n",
       "      <td>[art, basel, swiss, centerpiec, of, the, trade...</td>\n",
       "      <td>10</td>\n",
       "      <td>2.968558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>Dealers were looking to the event as a bellwet...</td>\n",
       "      <td>[dealer, were, look, to, the, event, as, a, be...</td>\n",
       "      <td>18</td>\n",
       "      <td>3.599777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    s_id                                      original_sent  \\\n",
       "471  472  When President Barack Obama gave his farewell ...   \n",
       "472  473                     For Elite Golfers, Money Talks   \n",
       "473  474  Sponsors have long paid players to compete in ...   \n",
       "474  475  Art Basel, Swiss Centerpiece of the Trade’s Ye...   \n",
       "475  476  Dealers were looking to the event as a bellwet...   \n",
       "\n",
       "                                          stemmed_sent num_word  skl_weight  \n",
       "471  [when, presid, barack, obama, gave, hi, farewe...       56    6.414338  \n",
       "472                   [for, elit, golfer, money, talk]        5    2.172869  \n",
       "473  [sponsor, have, long, paid, player, to, compet...       24    4.296807  \n",
       "474  [art, basel, swiss, centerpiec, of, the, trade...       10    2.968558  \n",
       "475  [dealer, were, look, to, the, event, as, a, be...       18    3.599777  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weight['skl_weight'] = tfidf_list\n",
    "df_weight.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328469f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    s_id                                      original_sent  \\\n",
      "471  472  When President Barack Obama gave his farewell ...   \n",
      "472  473                     For Elite Golfers, Money Talks   \n",
      "473  474  Sponsors have long paid players to compete in ...   \n",
      "474  475  Art Basel, Swiss Centerpiece of the Trade’s Ye...   \n",
      "475  476  Dealers were looking to the event as a bellwet...   \n",
      "\n",
      "                                          stemmed_sent num_word  skl_weight  \\\n",
      "471  [when, presid, barack, obama, gave, hi, farewe...       56    6.414338   \n",
      "472                   [for, elit, golfer, money, talk]        5    2.172869   \n",
      "473  [sponsor, have, long, paid, player, to, compet...       24    4.296807   \n",
      "474  [art, basel, swiss, centerpiec, of, the, trade...       10    2.968558   \n",
      "475  [dealer, were, look, to, the, event, as, a, be...       18    3.599777   \n",
      "\n",
      "     nskl_weight  \n",
      "471     0.114542  \n",
      "472     0.434574  \n",
      "473     0.179034  \n",
      "474     0.296856  \n",
      "475     0.199988  \n"
     ]
    }
   ],
   "source": [
    "total_w = 0\n",
    "norm_w_list = []\n",
    "for i, row in df_weight.iterrows():   \n",
    "    num = row['num_word']\n",
    "    weight = row['skl_weight']\n",
    "    if num != 0:\n",
    "        norm_w_list.append(weight/num)\n",
    "    else:\n",
    "        print('There is no sentence.')\n",
    "        \n",
    "    \n",
    "df_weight['nskl_weight'] = norm_w_list\n",
    "print(df_weight.tail())\n",
    "\n",
    "for i, row in df_weight.iterrows():           \n",
    "    total_w += row['nskl_weight']\n",
    "    \n",
    "ave_skl_weight = total_w / len(df_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aca65e",
   "metadata": {},
   "source": [
    "# Gensim TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61d459a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dealers', 'were', 'looking', 'to', 'the', 'event', 'as', 'bellwether', 'for', 'return', 'to', 'normality', 'in', 'the', 'art', 'world']\n"
     ]
    }
   ],
   "source": [
    "g_token = [simple_preprocess(s) for s in unst_sen_list]\n",
    "print(g_token[475])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a577ddb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    s_id                                      original_sent  \\\n",
      "471  472  When President Barack Obama gave his farewell ...   \n",
      "472  473                     For Elite Golfers, Money Talks   \n",
      "473  474  Sponsors have long paid players to compete in ...   \n",
      "474  475  Art Basel, Swiss Centerpiece of the Trade’s Ye...   \n",
      "475  476  Dealers were looking to the event as a bellwet...   \n",
      "\n",
      "                                          stemmed_sent num_word  skl_weight  \\\n",
      "471  [when, presid, barack, obama, gave, hi, farewe...       56    6.414338   \n",
      "472                   [for, elit, golfer, money, talk]        5    2.172869   \n",
      "473  [sponsor, have, long, paid, player, to, compet...       24    4.296807   \n",
      "474  [art, basel, swiss, centerpiec, of, the, trade...       10    2.968558   \n",
      "475  [dealer, were, look, to, the, event, as, a, be...       18    3.599777   \n",
      "\n",
      "     nskl_weight  gen_weight  ngen_weight  \n",
      "471     0.114542    6.285033     0.146164  \n",
      "472     0.434574    2.130364     0.426073  \n",
      "473     0.179034    4.155556     0.197884  \n",
      "474     0.296856    2.837373     0.283737  \n",
      "475     0.199988    3.414167     0.243869  \n"
     ]
    }
   ],
   "source": [
    "# weight_{i,j} = frequency_{i,j} * log_2(D / document_freq_{i})\n",
    "g_token = [simple_preprocess(s) for s in unst_sen_list]\n",
    "dictionary = corpora.Dictionary()\n",
    "g_bow = [dictionary.doc2bow(t, allow_update=True) for t in g_token]\n",
    "g_map = dictionary.token2id\n",
    "# g_map = dict((y,x) for x,y in g_map.iteritems())\n",
    "g_map = { g_map[k]:k for k in g_map}\n",
    "# print(g_map)\n",
    "\n",
    "g_tfidf = models.TfidfModel(g_bow, smartirs='ntc')\n",
    "# 儲存、載入模型\n",
    "# g_tfidf.save(\"g_tfidf.tfidf\")\n",
    "# g_tfidf = models.TfidfModel.load(\"g_tfidf.tfidf\")\n",
    "\n",
    "genw_list = []\n",
    "genw_norm_list = []\n",
    "gen_dict = {}\n",
    "for i, sen in enumerate(g_tfidf[g_bow]):\n",
    "    # print([[dictionary[word], freq] for word, freq in sen])\n",
    "    w = 0\n",
    "    for j, freq in sen:\n",
    "        w += freq\n",
    "        word = g_map[j]\n",
    "        if word not in list_sw:\n",
    "            if word in gen_dict:\n",
    "                gen_dict[word] =  gen_dict[word] + freq\n",
    "                # print('existed word:', word, 'word_w:', gen_dict[word])\n",
    "            else:\n",
    "                gen_dict[word] = freq\n",
    "                # print('word:', word, 'word_w:', gen_dict[word])\n",
    "        \n",
    "    norm_w = w / len(sen)\n",
    "    genw_list.append(w)\n",
    "    genw_norm_list.append(norm_w)\n",
    "        \n",
    "df_weight['gen_weight'] = genw_list \n",
    "df_weight['ngen_weight'] = genw_norm_list\n",
    "print(df_weight.tail())\n",
    "gen_dict = dict(sorted(gen_dict.items(), key=lambda item: item[1], reverse=True)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0f9bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_weight.iterrows():           \n",
    "    total_w += row['ngen_weight']\n",
    "    \n",
    "ave_gen_weight = total_w / len(df_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3221a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f35777",
   "metadata": {},
   "source": [
    "# Get Relevant Sentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d88cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(output, query):\n",
    "    r = output.most_similar(positive=[query])\n",
    "    # print(query,'(3):\\n', r)\n",
    "    # for i in range(num):\n",
    "    #    top_list.append(r[i][0])\n",
    "    top = r[0][0]\n",
    "    print('query:', query, ', the closest:', top)\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9a4844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_sent  stemmed_sent num_word skl_weight  nskl_weight  gen_weight  ngen_weigh\n",
    "def get_evidence_sentence(df_weight, query, closest, col):\n",
    "    top_w = 0\n",
    "    top_sen = ''\n",
    "    q_w = 0\n",
    "    q_sen = ''\n",
    "    c_w = 0\n",
    "    c_sen = ''\n",
    "    for i, row in df_weight.iterrows():   \n",
    "        s = row['stemmed_sent']\n",
    "        ori_s = row['original_sent']\n",
    "        w = row[col] #norm\n",
    "\n",
    "        if query in s and w > q_w:\n",
    "            q_sen = ori_s\n",
    "            q_w = w\n",
    "\n",
    "        if closest in s and w > c_w:\n",
    "            c_sen = ori_s\n",
    "            c_w = w\n",
    "\n",
    "        if query in s and closest in s and w > top_w:\n",
    "            top_w = w\n",
    "            top_sen = ori_s\n",
    "\n",
    "        if i == len(df_weight) -1:\n",
    "            if top_w == 0 and top_sen == '':\n",
    "                colored_text = []\n",
    "                for c in re.split(r'(;|,|:|\\s|[()])\\s*', q_sen):\n",
    "                    c_stem = ps.stem(c)\n",
    "                    if query in c_stem:\n",
    "                        colored_text.append(colored(c, 'grey','on_yellow'))\n",
    "\n",
    "                    else:\n",
    "                        colored_text.append(c)\n",
    "\n",
    "                q_sen = \"\".join(colored_text)\n",
    "\n",
    "                colored_text = []            \n",
    "                for c in re.split(r'(;|,|:|\\s|[()])\\s*', c_sen):\n",
    "                    c_stem = ps.stem(c)\n",
    "                    if closest in c_stem:\n",
    "                        colored_text.append(colored(c, 'grey','on_yellow'))\n",
    "\n",
    "                    else:\n",
    "                        colored_text.append(c)\n",
    "\n",
    "                c_sen = \"\".join(colored_text)\n",
    "\n",
    "                print('\\nThere is no sentence including both',query, 'and', closest + '.')\n",
    "                print('However, we can get sentences with the maximum weight seperately: \\na.', \n",
    "                      q_sen, '(', q_w, ') \\nand \\nb.',  c_sen, '(', c_w, ').' )\n",
    "\n",
    "\n",
    "            else:\n",
    "                colored_text = []            \n",
    "                for c in re.split(r'(;|,|:|\\s|[()])\\s*', top_sen):\n",
    "                    c_stem = ps.stem(c)\n",
    "                    if query in c_stem or closest in c_stem:\n",
    "                        colored_text.append(colored(c, 'grey','on_yellow'))\n",
    "\n",
    "                    else:\n",
    "                        colored_text.append(c)\n",
    "\n",
    "                top_sen = \"\".join(colored_text)\n",
    "                print('\\nThe proof sentence is: \\n\"', top_sen, '\"\\n, whose', col,'is:', str(top_w) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "495cfbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top cbow words: ['travel', 'coronaviru', 'presid', 'new', 'trump', 'pandem', 'ha', 'biden', 'wa', 'year', 'thi', 'state', 'countri', 'week', 'world', 'hi', 'one', 'said', 'inaugur', 'place']\n",
      "\n",
      "top sklearn tf-idf: \n",
      "               word    weight\n",
      "1422        travel  8.421899\n",
      "320    coronavirus  7.652863\n",
      "900            new  6.285331\n",
      "137          biden  6.179987\n",
      "957       pandemic  5.994815\n",
      "1043     president  5.951106\n",
      "999         places  5.652918\n",
      "1508          week  4.913102\n",
      "1542          year  4.882280\n",
      "1533         world  4.543223\n",
      "8             2021  4.488951\n",
      "1186          said  4.201798\n",
      "1435         trump  4.147086\n",
      "934            one  4.110811\n",
      "658   inauguration  3.678143\n",
      "779           list  3.572476\n",
      "1465            us  3.569469\n",
      "613          heres  3.532351\n",
      "522          first  3.462417\n",
      "1308        states  3.417919\n",
      "\n",
      "top gensim tf-idf: ['travel', 'coronavirus', 'places', 'biden', 'president', 'new', 'pandemic', 'week', 'year', 'world', 'said', 'trump', 'one', 'inauguration', 'heres', 'list', 'us', 'first', 'states', 'love']\n"
     ]
    }
   ],
   "source": [
    "print('top cbow words:', list_text[0:20])\n",
    "print('\\ntop sklearn tf-idf: \\n', df_temp.head(20))\n",
    "print('\\ntop gensim tf-idf:',list(gen_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f131d3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please input a query:travel\n"
     ]
    }
   ],
   "source": [
    "query = input('please input a query:')\n",
    "# travel, coronaviru, world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de703aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: travel , the closest: pro\n",
      "\n",
      "There is no sentence including both travel and pro.\n",
      "However, we can get sentences with the maximum weight seperately: \n",
      "a. The \u001b[43m\u001b[30mTravel\u001b[0m Industry Pitches In ( 0.4053430552034163 ) \n",
      "and \n",
      "b. With Positive Tests,Australia’s Summer of \u001b[43m\u001b[30mPro\u001b[0m Tennis Has a Rocky Start ( 0.26804844827199165 ).\n",
      "The average sklweight of all sentences is 0.2870859267054441.\n",
      "\n",
      "There is no sentence including both travel and pro.\n",
      "However, we can get sentences with the maximum weight seperately: \n",
      "a. It’s a very 2020 — wait,2021 — \u001b[43m\u001b[30mtravel\u001b[0m predicament. ( 0.4262432052060518 ) \n",
      "and \n",
      "b. With Positive Tests,Australia’s Summer of \u001b[43m\u001b[30mPro\u001b[0m Tennis Has a Rocky Start ( 0.28575333317091034 ).\n",
      "The average genweight of all sentences is 0.5881379576898975.\n"
     ]
    }
   ],
   "source": [
    "cbow_output_3 = gensim.models.KeyedVectors.load_word2vec_format('3d_vectors.txt', binary=False, encoding='unicode_escape')\n",
    "\n",
    "closest = find_most_similar(cbow_output_3, query)\n",
    "\n",
    "get_evidence_sentence(df_weight, query, closest, 'nskl_weight')\n",
    "print('The average sklweight of all sentences is', str(ave_skl_weight) +'.')\n",
    "\n",
    "get_evidence_sentence(df_weight, query, closest, 'ngen_weight')\n",
    "print('The average genweight of all sentences is', str(ave_gen_weight) +'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98b8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1582a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c4d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c520571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1b961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365a3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32289a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab66c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf921ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_weight = df_weight.sort_values('nskl_weight', ascending= False)\n",
    "# df_skl = df_weight[['original_sent','nskl_weight']]\n",
    "# print(df_skl.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa5d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
